<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Google Books NGrams</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>





</head>

<body>
<h1>Google Books NGrams</h1>

<p>The Google books ngrams project created a huge amount of data about words contained in books that have been scanned into the Google Books collection.  For each book, each occurance of a word was counted and the year of publication was noted. Then data for each word was created that has these variables:</p>

<ul>
<li>word</li>
<li>year</li>
<li>total number of occurances</li>
<li>total number of books</li>
</ul>

<p>These single words are called 1-grams. Pairs of words that occur together, or 2-grams, were also computed, along with 3-, 4-, and 5-grams.</p>

<p><a href="http://books.google.com/ngrams">The NGrams Viewer</a> is a great tool for trying some preliminary analyses.  Open it in another browser window.  To get started, try these searches using these words:</p>

<ul>
<li>feminism</li>
<li>communism, socialism</li>
<li>PC, typewriter, teletype, telegraph, email</li>
<li>podcast, broadcast</li>
<li>radio, television</li>
</ul>

<p>Can you think of some others that might be interesting to try?</p>

<p>What does the plot represent?  Read on&hellip;</p>

<h2>Additional Information about Ngram searching</h2>

<p>You can find more details on the <a href="http://books.google.com/ngrams/info">information page for Google Ngrams</a>.  Look at that page and note how you can combine NGrams together by using the &#39;+&#39; sign, such as:  </p>

<ul>
<li>game + sport</li>
<li>radio, television, internet+web</li>
</ul>

<p>Recall the reading/audiocast for this week, where the work by Bently and colleagues hypothesized that perhaps words conveying certain emotions could tell us something about the human condition over time (&ldquo;emotional archelogy&rdquo;).  Here are some sets of words to try for our relative joy and sadness:</p>

<p>joy + glee + amusement + ecstasy + gaiety + euphoria + bliss + elation + delight + happiness + jubilation, sad + depression + unhappiness + misery + melancholy + gloom + despair</p>

<p>Or these for fear:</p>

<p>panic + terror + hysteria + horror + fear</p>

<h2>Raw Data Available</h2>

<p>Anyone can get <a href="http://storage.googleapis.com/books/ngrams/books/datasetsv2.html">the NGram project data</a> and try analyses such as Bently and his colleagues did.  There are many interesting possibilities with this vast amount of data.</p>

</body>

</html>

